{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pickle import dump,load\n",
    "from random import randint\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "with open(\"moby_dick_four_chapters.txt\") as f:\n",
    "    doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading spacy model for preprocessing the text\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'tagger','ner'])\n",
    "\n",
    "# Gives error if length> 1m so text length needs to be set explicitly\n",
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean unnecessary tokens that d cause overfitting\n",
    "\n",
    "def clean_text(doc):\n",
    "    return [token.text.lower() for token in nlp(doc) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = clean_text(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11394"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating sequences of tokens\n",
    "\n",
    "# 25 training words , then one target word\n",
    "train_len = 25+1 \n",
    "\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    \n",
    "    # grabbing train_len 26 words\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    # adding to list of sequences\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11368"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encoding words in sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 964,   14,  265,   51,  263,  416,   87,  222,  129,  111],\n",
       "       [  14,  265,   51,  263,  416,   87,  222,  129,  111,  962],\n",
       "       [ 265,   51,  263,  416,   87,  222,  129,  111,  962,  262],\n",
       "       [  51,  263,  416,   87,  222,  129,  111,  962,  262,   50],\n",
       "       [ 263,  416,   87,  222,  129,  111,  962,  262,   50,   43],\n",
       "       [ 416,   87,  222,  129,  111,  962,  262,   50,   43,   37],\n",
       "       [  87,  222,  129,  111,  962,  262,   50,   43,   37,  321],\n",
       "       [ 222,  129,  111,  962,  262,   50,   43,   37,  321,    7],\n",
       "       [ 129,  111,  962,  262,   50,   43,   37,  321,    7,   23],\n",
       "       [ 111,  962,  262,   50,   43,   37,  321,    7,   23,  555],\n",
       "       [ 962,  262,   50,   43,   37,  321,    7,   23,  555,    3],\n",
       "       [ 262,   50,   43,   37,  321,    7,   23,  555,    3,  150],\n",
       "       [  50,   43,   37,  321,    7,   23,  555,    3,  150,  261],\n",
       "       [  43,   37,  321,    7,   23,  555,    3,  150,  261,    6],\n",
       "       [  37,  321,    7,   23,  555,    3,  150,  261,    6, 2704],\n",
       "       [ 321,    7,   23,  555,    3,  150,  261,    6, 2704,   14],\n",
       "       [   7,   23,  555,    3,  150,  261,    6, 2704,   14,   24],\n",
       "       [  23,  555,    3,  150,  261,    6, 2704,   14,   24,  965],\n",
       "       [ 555,    3,  150,  261,    6, 2704,   14,   24,  965,    5],\n",
       "       [   3,  150,  261,    6, 2704,   14,   24,  965,    5,   60],\n",
       "       [ 150,  261,    6, 2704,   14,   24,  965,    5,   60,    5],\n",
       "       [ 261,    6, 2704,   14,   24,  965,    5,   60,    5,   56],\n",
       "       [   6, 2704,   14,   24,  965,    5,   60,    5,   56,  322],\n",
       "       [2704,   14,   24,  965,    5,   60,    5,   56,  322,   38],\n",
       "       [  14,   24,  965,    5,   60,    5,   56,  322,   38,    2],\n",
       "       [  24,  965,    5,   60,    5,   56,  322,   38,    2,   50]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replaced words in text with particular ids \n",
    "# sequences with shifting one word over\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training and target sequences\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2709"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras padding sequences need an extra space to hold zero\n",
    "y = to_categorical(y, num_classes=vocabulary_size+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1] # setting seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocabulary_size+1,output_dim=seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(seq_len*2, return_sequences=True))\n",
    "    model.add(LSTM(seq_len*2))\n",
    "    model.add(Dense(seq_len*6, activation='relu'))\n",
    "\n",
    "    model.add(Dense(vocabulary_size+1, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\WorkPC\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            67750     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 50)            15200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               7650      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2710)              409210    \n",
      "=================================================================\n",
      "Total params: 520,010\n",
      "Trainable params: 520,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11368/11368 [==============================] - 4s 347us/step - loss: 6.2718 - acc: 0.0527\n",
      "Epoch 2/200\n",
      "11368/11368 [==============================] - 4s 346us/step - loss: 6.1578 - acc: 0.0527\n",
      "Epoch 3/200\n",
      "11368/11368 [==============================] - 4s 353us/step - loss: 6.0933 - acc: 0.0527 1s - loss: 6.0998 - acc: 0.05 - ETA: 1s - loss: \n",
      "Epoch 4/200\n",
      "11368/11368 [==============================] - 4s 348us/step - loss: 5.9862 - acc: 0.0544\n",
      "Epoch 5/200\n",
      "11368/11368 [==============================] - 4s 353us/step - loss: 5.8850 - acc: 0.0560\n",
      "Epoch 6/200\n",
      "11368/11368 [==============================] - 5s 400us/step - loss: 5.8134 - acc: 0.0663\n",
      "Epoch 7/200\n",
      "11368/11368 [==============================] - 5s 415us/step - loss: 5.7466 - acc: 0.0669\n",
      "Epoch 8/200\n",
      "11368/11368 [==============================] - 5s 423us/step - loss: 5.6895 - acc: 0.0678\n",
      "Epoch 9/200\n",
      "11368/11368 [==============================] - 5s 405us/step - loss: 5.6288 - acc: 0.0704\n",
      "Epoch 10/200\n",
      "11368/11368 [==============================] - 5s 404us/step - loss: 5.5537 - acc: 0.0742\n",
      "Epoch 11/200\n",
      "11368/11368 [==============================] - 5s 408us/step - loss: 5.4863 - acc: 0.0733\n",
      "Epoch 12/200\n",
      "11368/11368 [==============================] - 5s 405us/step - loss: 5.4188 - acc: 0.0760\n",
      "Epoch 13/200\n",
      "11368/11368 [==============================] - 5s 405us/step - loss: 5.3513 - acc: 0.0786\n",
      "Epoch 14/200\n",
      "11368/11368 [==============================] - 5s 404us/step - loss: 5.2812 - acc: 0.0795\n",
      "Epoch 15/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 5.2175 - acc: 0.0815\n",
      "Epoch 16/200\n",
      "11368/11368 [==============================] - 5s 404us/step - loss: 5.1579 - acc: 0.0819\n",
      "Epoch 17/200\n",
      "11368/11368 [==============================] - 5s 405us/step - loss: 5.0995 - acc: 0.0848\n",
      "Epoch 18/200\n",
      "11368/11368 [==============================] - 5s 414us/step - loss: 5.0479 - acc: 0.0852\n",
      "Epoch 19/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 4.9957 - acc: 0.0865\n",
      "Epoch 20/200\n",
      "11368/11368 [==============================] - 5s 406us/step - loss: 4.9477 - acc: 0.0895\n",
      "Epoch 21/200\n",
      "11368/11368 [==============================] - 5s 409us/step - loss: 4.9006 - acc: 0.0903\n",
      "Epoch 22/200\n",
      "11368/11368 [==============================] - 5s 424us/step - loss: 4.8540 - acc: 0.0926\n",
      "Epoch 23/200\n",
      "11368/11368 [==============================] - 5s 406us/step - loss: 4.8050 - acc: 0.0932\n",
      "Epoch 24/200\n",
      "11368/11368 [==============================] - 5s 404us/step - loss: 4.7592 - acc: 0.0949\n",
      "Epoch 25/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 4.7158 - acc: 0.0966\n",
      "Epoch 26/200\n",
      "11368/11368 [==============================] - 5s 406us/step - loss: 4.6650 - acc: 0.0979\n",
      "Epoch 27/200\n",
      "11368/11368 [==============================] - 5s 408us/step - loss: 4.6197 - acc: 0.1000\n",
      "Epoch 28/200\n",
      "11368/11368 [==============================] - 5s 406us/step - loss: 4.5802 - acc: 0.1005\n",
      "Epoch 29/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 4.5378 - acc: 0.1013\n",
      "Epoch 30/200\n",
      "11368/11368 [==============================] - 5s 408us/step - loss: 4.5007 - acc: 0.1027\n",
      "Epoch 31/200\n",
      "11368/11368 [==============================] - 5s 415us/step - loss: 4.4578 - acc: 0.1018\n",
      "Epoch 32/200\n",
      "11368/11368 [==============================] - 5s 406us/step - loss: 4.4202 - acc: 0.1044\n",
      "Epoch 33/200\n",
      "11368/11368 [==============================] - 5s 408us/step - loss: 4.3940 - acc: 0.1042\n",
      "Epoch 34/200\n",
      "11368/11368 [==============================] - 5s 408us/step - loss: 4.3468 - acc: 0.1090\n",
      "Epoch 35/200\n",
      "11368/11368 [==============================] - 5s 408us/step - loss: 4.3100 - acc: 0.1064\n",
      "Epoch 36/200\n",
      "11368/11368 [==============================] - 5s 429us/step - loss: 4.2822 - acc: 0.1122\n",
      "Epoch 37/200\n",
      "11368/11368 [==============================] - 5s 413us/step - loss: 4.2429 - acc: 0.1137\n",
      "Epoch 38/200\n",
      "11368/11368 [==============================] - 5s 410us/step - loss: 4.2022 - acc: 0.1169\n",
      "Epoch 39/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 4.1701 - acc: 0.1201\n",
      "Epoch 40/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 4.1379 - acc: 0.1207\n",
      "Epoch 41/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 4.0930 - acc: 0.1281\n",
      "Epoch 42/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 4.0613 - acc: 0.1335\n",
      "Epoch 43/200\n",
      "11368/11368 [==============================] - 5s 411us/step - loss: 4.0263 - acc: 0.1329\n",
      "Epoch 44/200\n",
      "11368/11368 [==============================] - 5s 415us/step - loss: 3.9893 - acc: 0.1392\n",
      "Epoch 45/200\n",
      "11368/11368 [==============================] - 5s 408us/step - loss: 3.9532 - acc: 0.1387\n",
      "Epoch 46/200\n",
      "11368/11368 [==============================] - 5s 409us/step - loss: 3.9154 - acc: 0.1475\n",
      "Epoch 47/200\n",
      "11368/11368 [==============================] - 5s 410us/step - loss: 3.8836 - acc: 0.1512\n",
      "Epoch 48/200\n",
      "11368/11368 [==============================] - 5s 409us/step - loss: 3.8466 - acc: 0.1568\n",
      "Epoch 49/200\n",
      "11368/11368 [==============================] - 5s 407us/step - loss: 3.8031 - acc: 0.1595\n",
      "Epoch 50/200\n",
      "11368/11368 [==============================] - 5s 434us/step - loss: 3.7716 - acc: 0.1670\n",
      "Epoch 51/200\n",
      "11368/11368 [==============================] - 5s 412us/step - loss: 3.7356 - acc: 0.1714\n",
      "Epoch 52/200\n",
      "11368/11368 [==============================] - 5s 409us/step - loss: 3.6925 - acc: 0.1747\n",
      "Epoch 53/200\n",
      "11368/11368 [==============================] - 5s 410us/step - loss: 3.6481 - acc: 0.1841\n",
      "Epoch 54/200\n",
      "11368/11368 [==============================] - 5s 411us/step - loss: 3.6120 - acc: 0.1896\n",
      "Epoch 55/200\n",
      "11368/11368 [==============================] - 5s 413us/step - loss: 3.5755 - acc: 0.1935\n",
      "Epoch 56/200\n",
      "11368/11368 [==============================] - 5s 418us/step - loss: 3.5373 - acc: 0.2003\n",
      "Epoch 57/200\n",
      "11368/11368 [==============================] - 5s 415us/step - loss: 3.4996 - acc: 0.2094\n",
      "Epoch 58/200\n",
      "11368/11368 [==============================] - 5s 412us/step - loss: 3.4562 - acc: 0.2153\n",
      "Epoch 59/200\n",
      "11368/11368 [==============================] - 5s 411us/step - loss: 3.4297 - acc: 0.2185\n",
      "Epoch 60/200\n",
      "11368/11368 [==============================] - 5s 412us/step - loss: 3.3940 - acc: 0.2237\n",
      "Epoch 61/200\n",
      "11368/11368 [==============================] - 5s 413us/step - loss: 3.3480 - acc: 0.2320\n",
      "Epoch 62/200\n",
      "11368/11368 [==============================] - 5s 414us/step - loss: 3.3131 - acc: 0.2381\n",
      "Epoch 63/200\n",
      "11368/11368 [==============================] - 5s 414us/step - loss: 3.2817 - acc: 0.2447\n",
      "Epoch 64/200\n",
      "11368/11368 [==============================] - 5s 438us/step - loss: 3.2472 - acc: 0.2498\n",
      "Epoch 65/200\n",
      "11368/11368 [==============================] - 5s 414us/step - loss: 3.2080 - acc: 0.2573\n",
      "Epoch 66/200\n",
      "11368/11368 [==============================] - 5s 413us/step - loss: 3.1728 - acc: 0.2647\n",
      "Epoch 67/200\n",
      "11368/11368 [==============================] - 5s 416us/step - loss: 3.1370 - acc: 0.2667\n",
      "Epoch 68/200\n",
      "11368/11368 [==============================] - 5s 414us/step - loss: 3.1040 - acc: 0.2729\n",
      "Epoch 69/200\n",
      "11368/11368 [==============================] - 5s 424us/step - loss: 3.0714 - acc: 0.2816\n",
      "Epoch 70/200\n",
      "11368/11368 [==============================] - 5s 416us/step - loss: 3.0405 - acc: 0.2883\n",
      "Epoch 71/200\n",
      "11368/11368 [==============================] - 5s 417us/step - loss: 3.0012 - acc: 0.2883\n",
      "Epoch 72/200\n",
      "11368/11368 [==============================] - 5s 418us/step - loss: 2.9650 - acc: 0.2999\n",
      "Epoch 73/200\n",
      "11368/11368 [==============================] - 5s 420us/step - loss: 2.9274 - acc: 0.3110\n",
      "Epoch 74/200\n",
      "11368/11368 [==============================] - 5s 421us/step - loss: 2.8970 - acc: 0.3164\n",
      "Epoch 75/200\n",
      "11368/11368 [==============================] - 5s 422us/step - loss: 2.8673 - acc: 0.3200\n",
      "Epoch 76/200\n",
      "11368/11368 [==============================] - 5s 423us/step - loss: 2.8353 - acc: 0.3247\n",
      "Epoch 77/200\n",
      "11368/11368 [==============================] - 5s 433us/step - loss: 2.7950 - acc: 0.3365\n",
      "Epoch 78/200\n",
      "11368/11368 [==============================] - 5s 443us/step - loss: 2.7593 - acc: 0.3421\n",
      "Epoch 79/200\n",
      "11368/11368 [==============================] - 5s 429us/step - loss: 2.7199 - acc: 0.3529\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11368/11368 [==============================] - 5s 422us/step - loss: 2.6877 - acc: 0.3557\n",
      "Epoch 81/200\n",
      "11368/11368 [==============================] - 5s 428us/step - loss: 2.6665 - acc: 0.3588\n",
      "Epoch 82/200\n",
      "11368/11368 [==============================] - 5s 431us/step - loss: 2.6380 - acc: 0.3629\n",
      "Epoch 83/200\n",
      "11368/11368 [==============================] - 5s 429us/step - loss: 2.6052 - acc: 0.3681\n",
      "Epoch 84/200\n",
      "11368/11368 [==============================] - 5s 432us/step - loss: 2.5736 - acc: 0.3757\n",
      "Epoch 85/200\n",
      "11368/11368 [==============================] - 5s 445us/step - loss: 2.5422 - acc: 0.3836\n",
      "Epoch 86/200\n",
      "11368/11368 [==============================] - 5s 449us/step - loss: 2.5100 - acc: 0.3841\n",
      "Epoch 87/200\n",
      "11368/11368 [==============================] - 5s 453us/step - loss: 2.4780 - acc: 0.4007\n",
      "Epoch 88/200\n",
      "11368/11368 [==============================] - 5s 459us/step - loss: 2.4604 - acc: 0.3987\n",
      "Epoch 89/200\n",
      "11368/11368 [==============================] - 5s 453us/step - loss: 2.4346 - acc: 0.4063\n",
      "Epoch 90/200\n",
      "11368/11368 [==============================] - 5s 446us/step - loss: 2.3984 - acc: 0.4138\n",
      "Epoch 91/200\n",
      "11368/11368 [==============================] - 6s 514us/step - loss: 2.3724 - acc: 0.4183\n",
      "Epoch 92/200\n",
      "11368/11368 [==============================] - 5s 456us/step - loss: 2.3526 - acc: 0.4187\n",
      "Epoch 93/200\n",
      "11368/11368 [==============================] - 5s 471us/step - loss: 2.3203 - acc: 0.4302\n",
      "Epoch 94/200\n",
      "11368/11368 [==============================] - 5s 458us/step - loss: 2.2900 - acc: 0.4337 1s - l\n",
      "Epoch 95/200\n",
      "11368/11368 [==============================] - 5s 459us/step - loss: 2.2551 - acc: 0.4424\n",
      "Epoch 96/200\n",
      "11368/11368 [==============================] - 5s 464us/step - loss: 2.2350 - acc: 0.4502 1s -\n",
      "Epoch 97/200\n",
      "11368/11368 [==============================] - 5s 472us/step - loss: 2.2194 - acc: 0.4502 0s - loss: 2.2186 - acc: 0.\n",
      "Epoch 98/200\n",
      "11368/11368 [==============================] - 5s 470us/step - loss: 2.1990 - acc: 0.4489 1s - lo\n",
      "Epoch 99/200\n",
      "11368/11368 [==============================] - 5s 479us/step - loss: 2.1673 - acc: 0.4578\n",
      "Epoch 100/200\n",
      "11368/11368 [==============================] - 5s 483us/step - loss: 2.1407 - acc: 0.4668 0s - loss: 2.1301 \n",
      "Epoch 101/200\n",
      "11368/11368 [==============================] - 6s 491us/step - loss: 2.1193 - acc: 0.4726\n",
      "Epoch 102/200\n",
      "11368/11368 [==============================] - 6s 498us/step - loss: 2.0918 - acc: 0.4784\n",
      "Epoch 103/200\n",
      "11368/11368 [==============================] - 6s 516us/step - loss: 2.0822 - acc: 0.4828 1s - loss: 2\n",
      "Epoch 104/200\n",
      "11368/11368 [==============================] - 6s 502us/step - loss: 2.0510 - acc: 0.4862\n",
      "Epoch 105/200\n",
      "11368/11368 [==============================] - 6s 505us/step - loss: 2.0276 - acc: 0.4934\n",
      "Epoch 106/200\n",
      "11368/11368 [==============================] - 6s 503us/step - loss: 2.0122 - acc: 0.4963\n",
      "Epoch 107/200\n",
      "11368/11368 [==============================] - 6s 520us/step - loss: 1.9804 - acc: 0.5043\n",
      "Epoch 108/200\n",
      "11368/11368 [==============================] - 6s 517us/step - loss: 1.9611 - acc: 0.5066\n",
      "Epoch 109/200\n",
      "11368/11368 [==============================] - 6s 539us/step - loss: 1.9341 - acc: 0.5143\n",
      "Epoch 110/200\n",
      "11368/11368 [==============================] - 6s 540us/step - loss: 1.9220 - acc: 0.5154\n",
      "Epoch 111/200\n",
      "11368/11368 [==============================] - 6s 550us/step - loss: 1.9083 - acc: 0.5157\n",
      "Epoch 112/200\n",
      "11368/11368 [==============================] - 6s 547us/step - loss: 1.8830 - acc: 0.5257\n",
      "Epoch 113/200\n",
      "11368/11368 [==============================] - 6s 549us/step - loss: 1.8615 - acc: 0.5323\n",
      "Epoch 114/200\n",
      "11368/11368 [==============================] - 7s 577us/step - loss: 1.8443 - acc: 0.5277\n",
      "Epoch 115/200\n",
      "11368/11368 [==============================] - 6s 561us/step - loss: 1.8108 - acc: 0.5384\n",
      "Epoch 116/200\n",
      "11368/11368 [==============================] - 6s 566us/step - loss: 1.7933 - acc: 0.5445\n",
      "Epoch 117/200\n",
      "11368/11368 [==============================] - 6s 569us/step - loss: 1.7872 - acc: 0.5436\n",
      "Epoch 118/200\n",
      "11368/11368 [==============================] - 7s 575us/step - loss: 1.7650 - acc: 0.5503\n",
      "Epoch 119/200\n",
      "11368/11368 [==============================] - 7s 580us/step - loss: 1.7594 - acc: 0.5514\n",
      "Epoch 120/200\n",
      "11368/11368 [==============================] - 7s 589us/step - loss: 1.7321 - acc: 0.5559\n",
      "Epoch 121/200\n",
      "11368/11368 [==============================] - 7s 589us/step - loss: 1.7134 - acc: 0.5596\n",
      "Epoch 122/200\n",
      "11368/11368 [==============================] - 7s 594us/step - loss: 1.6821 - acc: 0.5674\n",
      "Epoch 123/200\n",
      "11368/11368 [==============================] - 7s 601us/step - loss: 1.6654 - acc: 0.5753\n",
      "Epoch 124/200\n",
      "11368/11368 [==============================] - 7s 627us/step - loss: 1.6479 - acc: 0.5751\n",
      "Epoch 125/200\n",
      "11368/11368 [==============================] - 7s 612us/step - loss: 1.6269 - acc: 0.5802\n",
      "Epoch 126/200\n",
      "11368/11368 [==============================] - 7s 614us/step - loss: 1.6220 - acc: 0.5825\n",
      "Epoch 127/200\n",
      "11368/11368 [==============================] - 7s 625us/step - loss: 1.6190 - acc: 0.5814\n",
      "Epoch 128/200\n",
      "11368/11368 [==============================] - 7s 625us/step - loss: 1.5814 - acc: 0.5926\n",
      "Epoch 129/200\n",
      "11368/11368 [==============================] - 7s 631us/step - loss: 1.5613 - acc: 0.5990\n",
      "Epoch 130/200\n",
      "11368/11368 [==============================] - 7s 636us/step - loss: 1.5599 - acc: 0.5986\n",
      "Epoch 131/200\n",
      "11368/11368 [==============================] - 7s 638us/step - loss: 1.5490 - acc: 0.5981\n",
      "Epoch 132/200\n",
      "11368/11368 [==============================] - 7s 645us/step - loss: 1.5222 - acc: 0.6078\n",
      "Epoch 133/200\n",
      "11368/11368 [==============================] - 8s 673us/step - loss: 1.5053 - acc: 0.6136\n",
      "Epoch 134/200\n",
      "11368/11368 [==============================] - 7s 652us/step - loss: 1.4830 - acc: 0.6145\n",
      "Epoch 135/200\n",
      "11368/11368 [==============================] - 7s 658us/step - loss: 1.4760 - acc: 0.6217\n",
      "Epoch 136/200\n",
      "11368/11368 [==============================] - 8s 661us/step - loss: 1.4573 - acc: 0.6227\n",
      "Epoch 137/200\n",
      "11368/11368 [==============================] - 8s 669us/step - loss: 1.4376 - acc: 0.6274\n",
      "Epoch 138/200\n",
      "11368/11368 [==============================] - 8s 670us/step - loss: 1.4352 - acc: 0.6276\n",
      "Epoch 139/200\n",
      "11368/11368 [==============================] - 8s 680us/step - loss: 1.4106 - acc: 0.6371\n",
      "Epoch 140/200\n",
      "11368/11368 [==============================] - 8s 679us/step - loss: 1.3964 - acc: 0.6402\n",
      "Epoch 141/200\n",
      "11368/11368 [==============================] - 8s 687us/step - loss: 1.3837 - acc: 0.6407\n",
      "Epoch 142/200\n",
      "11368/11368 [==============================] - 8s 707us/step - loss: 1.3626 - acc: 0.6511\n",
      "Epoch 143/200\n",
      "11368/11368 [==============================] - 8s 703us/step - loss: 1.3484 - acc: 0.6514\n",
      "Epoch 144/200\n",
      "11368/11368 [==============================] - 8s 697us/step - loss: 1.3265 - acc: 0.6620\n",
      "Epoch 145/200\n",
      "11368/11368 [==============================] - 8s 702us/step - loss: 1.3188 - acc: 0.6577\n",
      "Epoch 146/200\n",
      "11368/11368 [==============================] - 8s 709us/step - loss: 1.3003 - acc: 0.6632\n",
      "Epoch 147/200\n",
      "11368/11368 [==============================] - 8s 713us/step - loss: 1.2915 - acc: 0.6610\n",
      "Epoch 148/200\n",
      "11368/11368 [==============================] - 8s 715us/step - loss: 1.2811 - acc: 0.6657\n",
      "Epoch 149/200\n",
      "11368/11368 [==============================] - 8s 719us/step - loss: 1.2535 - acc: 0.6725\n",
      "Epoch 150/200\n",
      "11368/11368 [==============================] - 8s 741us/step - loss: 1.2344 - acc: 0.6798\n",
      "Epoch 151/200\n",
      "11368/11368 [==============================] - 8s 729us/step - loss: 1.2433 - acc: 0.6769\n",
      "Epoch 152/200\n",
      "11368/11368 [==============================] - 8s 729us/step - loss: 1.2246 - acc: 0.6784\n",
      "Epoch 153/200\n",
      "11368/11368 [==============================] - 8s 735us/step - loss: 1.2053 - acc: 0.6875\n",
      "Epoch 154/200\n",
      "11368/11368 [==============================] - 8s 737us/step - loss: 1.1867 - acc: 0.6939\n",
      "Epoch 155/200\n",
      "11368/11368 [==============================] - ETA: 0s - loss: 1.1708 - acc: 0.694 - 8s 740us/step - loss: 1.1752 - acc: 0.6937\n",
      "Epoch 156/200\n",
      "11368/11368 [==============================] - 8s 745us/step - loss: 1.1628 - acc: 0.6961\n",
      "Epoch 157/200\n",
      "11368/11368 [==============================] - 9s 751us/step - loss: 1.1512 - acc: 0.7007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200\n",
      "11368/11368 [==============================] - 9s 759us/step - loss: 1.1385 - acc: 0.7050\n",
      "Epoch 159/200\n",
      "11368/11368 [==============================] - 9s 757us/step - loss: 1.1145 - acc: 0.7114\n",
      "Epoch 160/200\n",
      "11368/11368 [==============================] - 9s 758us/step - loss: 1.1062 - acc: 0.7135\n",
      "Epoch 161/200\n",
      "11368/11368 [==============================] - 9s 760us/step - loss: 1.0955 - acc: 0.7168\n",
      "Epoch 162/200\n",
      "11368/11368 [==============================] - 9s 763us/step - loss: 1.0783 - acc: 0.7222\n",
      "Epoch 163/200\n",
      "11368/11368 [==============================] - 9s 766us/step - loss: 1.0932 - acc: 0.7169\n",
      "Epoch 164/200\n",
      "11368/11368 [==============================] - 9s 772us/step - loss: 1.0596 - acc: 0.7247\n",
      "Epoch 165/200\n",
      "11368/11368 [==============================] - 9s 787us/step - loss: 1.0647 - acc: 0.7196\n",
      "Epoch 166/200\n",
      "11368/11368 [==============================] - 9s 783us/step - loss: 1.0324 - acc: 0.7308\n",
      "Epoch 167/200\n",
      "11368/11368 [==============================] - 9s 776us/step - loss: 1.0327 - acc: 0.7319\n",
      "Epoch 168/200\n",
      "11368/11368 [==============================] - 9s 777us/step - loss: 1.0077 - acc: 0.7424\n",
      "Epoch 169/200\n",
      "11368/11368 [==============================] - 9s 782us/step - loss: 0.9970 - acc: 0.7423\n",
      "Epoch 170/200\n",
      "11368/11368 [==============================] - 9s 786us/step - loss: 0.9788 - acc: 0.7482\n",
      "Epoch 171/200\n",
      "11368/11368 [==============================] - 9s 788us/step - loss: 0.9722 - acc: 0.7486\n",
      "Epoch 172/200\n",
      "11368/11368 [==============================] - 9s 799us/step - loss: 0.9580 - acc: 0.7542\n",
      "Epoch 173/200\n",
      "11368/11368 [==============================] - 9s 803us/step - loss: 0.9364 - acc: 0.7588\n",
      "Epoch 174/200\n",
      "11368/11368 [==============================] - 9s 797us/step - loss: 0.9430 - acc: 0.7540\n",
      "Epoch 175/200\n",
      "11368/11368 [==============================] - 9s 800us/step - loss: 0.9326 - acc: 0.7580\n",
      "Epoch 176/200\n",
      "11368/11368 [==============================] - 9s 801us/step - loss: 0.9174 - acc: 0.7650\n",
      "Epoch 177/200\n",
      "11368/11368 [==============================] - 9s 808us/step - loss: 0.9085 - acc: 0.7623\n",
      "Epoch 178/200\n",
      "11368/11368 [==============================] - 9s 807us/step - loss: 0.9098 - acc: 0.7643\n",
      "Epoch 179/200\n",
      "11368/11368 [==============================] - 9s 813us/step - loss: 0.8815 - acc: 0.7724\n",
      "Epoch 180/200\n",
      "11368/11368 [==============================] - 9s 832us/step - loss: 0.8863 - acc: 0.7662\n",
      "Epoch 181/200\n",
      "11368/11368 [==============================] - 9s 819us/step - loss: 0.8584 - acc: 0.7823\n",
      "Epoch 182/200\n",
      "11368/11368 [==============================] - 9s 830us/step - loss: 0.8438 - acc: 0.7869\n",
      "Epoch 183/200\n",
      "11368/11368 [==============================] - 9s 833us/step - loss: 0.8316 - acc: 0.7882\n",
      "Epoch 184/200\n",
      "11368/11368 [==============================] - 10s 890us/step - loss: 0.8176 - acc: 0.7910\n",
      "Epoch 185/200\n",
      "11368/11368 [==============================] - 10s 874us/step - loss: 0.8102 - acc: 0.7945\n",
      "Epoch 186/200\n",
      "11368/11368 [==============================] - 10s 906us/step - loss: 0.8037 - acc: 0.7943\n",
      "Epoch 187/200\n",
      "11368/11368 [==============================] - 10s 878us/step - loss: 0.8156 - acc: 0.7896\n",
      "Epoch 188/200\n",
      "11368/11368 [==============================] - 10s 846us/step - loss: 0.8106 - acc: 0.7899\n",
      "Epoch 189/200\n",
      "11368/11368 [==============================] - 10s 842us/step - loss: 0.7830 - acc: 0.7993\n",
      "Epoch 190/200\n",
      "11368/11368 [==============================] - 10s 837us/step - loss: 0.7918 - acc: 0.7964\n",
      "Epoch 191/200\n",
      "11368/11368 [==============================] - 10s 842us/step - loss: 0.7774 - acc: 0.7985\n",
      "Epoch 192/200\n",
      "11368/11368 [==============================] - 10s 854us/step - loss: 0.7435 - acc: 0.8118\n",
      "Epoch 193/200\n",
      "11368/11368 [==============================] - 10s 874us/step - loss: 0.7173 - acc: 0.8214\n",
      "Epoch 194/200\n",
      "11368/11368 [==============================] - 10s 886us/step - loss: 0.7369 - acc: 0.8131\n",
      "Epoch 195/200\n",
      "11368/11368 [==============================] - 10s 881us/step - loss: 0.7419 - acc: 0.8122\n",
      "Epoch 196/200\n",
      "11368/11368 [==============================] - 10s 856us/step - loss: 0.7150 - acc: 0.8176\n",
      "Epoch 197/200\n",
      "11368/11368 [==============================] - 10s 860us/step - loss: 0.6978 - acc: 0.8242\n",
      "Epoch 198/200\n",
      "11368/11368 [==============================] - 10s 871us/step - loss: 0.6737 - acc: 0.8336\n",
      "Epoch 199/200\n",
      "11368/11368 [==============================] - 10s 859us/step - loss: 0.6635 - acc: 0.8362\n",
      "Epoch 200/200\n",
      "11368/11368 [==============================] - 10s 885us/step - loss: 0.6598 - acc: 0.8353\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(X, y, batch_size=128, epochs=200,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('epoch_200.h5')\n",
    "\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = ' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[964,\n",
       "  14,\n",
       "  265,\n",
       "  51,\n",
       "  263,\n",
       "  416,\n",
       "  87,\n",
       "  222,\n",
       "  129,\n",
       "  111,\n",
       "  962,\n",
       "  262,\n",
       "  50,\n",
       "  43,\n",
       "  37,\n",
       "  321,\n",
       "  7,\n",
       "  23,\n",
       "  555,\n",
       "  3,\n",
       "  150,\n",
       "  261,\n",
       "  6,\n",
       "  2704,\n",
       "  14,\n",
       "  24]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([seed_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate specific number of words followings a seed text\n",
    "\n",
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "\n",
    "    output_text = []\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        encoded_text = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        seed_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shore i account trying that that the indecorous floor and hunted up the blackness i does trying to be peddling venture on a bed side'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
